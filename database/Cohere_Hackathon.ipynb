{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tqJzCpITKTZ"
      },
      "source": [
        "# Objectives\n",
        "1. Use Cohere in Langchain Framework\n",
        "  - https://python.langchain.com/docs/integrations/providers/cohere\n",
        "  - https://colab.research.google.com/github/cohere-ai/notebooks/blob/main/notebooks/Multilingual_Search_with_Cohere_and_Langchain.ipynb?ref=txt.cohere.com#scrollTo=s12ZE7vcHRJI\n",
        "    - Helped me to solve the cohere embeddings problem\n",
        "  - interestingly, you can use cohere's own RAG! (try that out!)\n",
        "\n",
        "2. Use Weaviate as the Vector database\n",
        "  - https://python.langchain.com/docs/integrations/vectorstores/weaviate\n",
        "3. Create a conversational agent w/ citation (interesting)\n",
        "\n",
        "Useful Information:\n",
        "- Multiquery generation (could replace with cohere's only implementation)\n",
        "  - https://python.langchain.com/docs/modules/data_connection/retrievers/MultiQueryRetriever?ref=blog.langchain.dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlV7o7paJNW5"
      },
      "source": [
        "## Prerequisite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkYuZFMVUDs5",
        "outputId": "1670d69d-ab6b-487a-8fb4-3a537bc5eacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH = '/content/drive/MyDrive/Cohere Hackathon/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x0JER-KEOef"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install cohere langchain weaviate-client PyPDF2 chromadb faiss-cpu openai sentence_transformers unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeZxL4WngTUc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "COHERE_API_KEY = 'BbUfe7pYwdcPQ1ByK313NDm0uiav1FpJMXWzU59R' # production key!!\n",
        "WEAVIATE_API_KEY = 'wHqgQrLferdBfKXGBxfF9t3wJStLxJ6aRXGb'\n",
        "WEAVIATE_URL = 'https://cohere-hackathon-v9totjun.weaviate.network'\n",
        "OPENAI_API_KEY = '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'\n",
        "\n",
        "# get from https://dashboard.cohere.com/api-keys\n",
        "os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY\n",
        "# get from https://console.weaviate.cloud/dashboard\n",
        "os.environ[\"WEAVIATE_API_KEY\"] = WEAVIATE_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blPmxUNzEJ45"
      },
      "outputs": [],
      "source": [
        "import cohere\n",
        "\n",
        "from weaviate.util import generate_uuid5\n",
        "\n",
        "from langchain.llms import Cohere\n",
        "from langchain.chat_models import ChatCohere\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings.cohere import CohereEmbeddings\n",
        "\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Weaviate\n",
        "from langchain.vectorstores import Chroma, FAISS\n",
        "import weaviate\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain.retrievers import ContextualCompressionRetriever, CohereRagRetriever\n",
        "from langchain.retrievers.document_compressors import CohereRerank\n",
        "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
        "\n",
        "from unidecode import unidecode\n",
        "\n",
        "import PyPDF2\n",
        "import time\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITLSZJx1JVeu"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAv4p7IkJ5a5"
      },
      "outputs": [],
      "source": [
        "# 0. get files from google drive\n",
        "def get_files(path: str, count=None) -> dict:\n",
        "\n",
        "    files = {}\n",
        "    for subdir in ['Proposal', 'RFP']:\n",
        "        subpath = os.path.join(PATH, subdir)\n",
        "        for i, project in enumerate(os.listdir(subpath)):\n",
        "            full_path = os.path.join(subpath, project)\n",
        "            files['{} {}'.format(project, subdir)] = [open(os.path.join(full_path, f), 'rb') for f in os.listdir(full_path)]\n",
        "\n",
        "            if count == i+1:\n",
        "                break\n",
        "    return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfG-SlO5lO_M"
      },
      "outputs": [],
      "source": [
        "# 1. Collect and process data\n",
        "# - index data appropriately using metadata\n",
        "def get_document(fileobj: object, project:str) -> list:\n",
        "    doc_combined = []\n",
        "\n",
        "    #create reader variable that will read the pdffileobj\n",
        "    reader = PyPDF2.PdfReader(fileobj)\n",
        "\n",
        "    #This will store the number of pages of this pdf file\n",
        "    num_pages = len(reader.pages)\n",
        "\n",
        "    timestamp = time.time()\n",
        "\n",
        "    for i in range(num_pages):\n",
        "        #create a variable that will select the selected number of pages\n",
        "        pageobj = reader.pages[i]\n",
        "        text = pageobj.extract_text()\n",
        "        text = unidecode(text)  # strips away all the unicode stuff\n",
        "\n",
        "        #split text recursively\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "        splits = text_splitter.split_text(text)\n",
        "\n",
        "        for j, t in enumerate(splits[:]):\n",
        "            metadata = {'source': project, 'filename': fileobj.name, 'page_number': str(i+1)}\n",
        "            doc_combined.append(Document(page_content=t, metadata=metadata))\n",
        "            # doc_combined.append(Document(page_content=t))\n",
        "    return doc_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHxF4PLJfuqV"
      },
      "outputs": [],
      "source": [
        "# 2. Settup VectorStore\n",
        "# Comments\n",
        "# a) use metadata to keep track of proposal data: https://python.langchain.com/docs/modules/data_connection/indexing - okay done\n",
        "\n",
        "def get_db(docs=[], create=False, use_cohere=False, device='cuda'):\n",
        "  # create vectorstore for retrieval --------------------------------\n",
        "  # what is wrong with cohere embeddings - okay now it works!\n",
        "  if use_cohere:\n",
        "    embeddings = CohereEmbeddings(model='embed-english-v3.0', cohere_api_key=COHERE_API_KEY)  # !!cohere embedding v3.0 requires to specify input_type!\n",
        "\n",
        "  else:\n",
        "    model_name = \"BAAI/bge-small-en\"\n",
        "    model_kwargs = {'device': device}\n",
        "    encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "    embeddings = HuggingFaceBgeEmbeddings(\n",
        "          model_name=model_name,\n",
        "          model_kwargs=model_kwargs,\n",
        "          encode_kwargs=encode_kwargs\n",
        "      )\n",
        "\n",
        "  client = weaviate.Client(\n",
        "        url=WEAVIATE_URL,\n",
        "        auth_client_secret=weaviate.AuthClientPassword(\n",
        "            username = 'siukai.cheung@mail.utoronto.ca',  # Replace w/ your WCS username\n",
        "            password = \"Kc97690461-\",  # Replace w/ your WCS password\n",
        "        ),\n",
        "    )\n",
        "\n",
        "  if create:\n",
        "\n",
        "    client.schema.delete_all()\n",
        "\n",
        "    db = Weaviate.from_documents(docs, embeddings, weaviate_url=WEAVIATE_URL, by_text=False, index_name='Cfa_proposal', text_key='text')\n",
        "    # db = FAISS.from_documents(docs, embeddings)\n",
        "  else:\n",
        "\n",
        "    # get the schema\n",
        "    schema = client.schema.get()\n",
        "\n",
        "    # print the schema\n",
        "    print(json.dumps(schema, indent=4))\n",
        "    db = Weaviate(client, index_name='Cfa_proposal', text_key='text', embedding=embeddings, by_text=False)\n",
        "\n",
        "  return db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC_CWI4lGAah"
      },
      "outputs": [],
      "source": [
        "# 3. set up the retriever chain w/ Cohere rerank\n",
        "def get_response(db, use_cohere_rag=False, docs=[]):\n",
        "    ''' Inspired by the top k and n semantic search approach '''\n",
        "    retriever = db.as_retriever(\n",
        "      search_kwargs={\"k\": 10}\n",
        "    )\n",
        "\n",
        "    if use_cohere_rag:\n",
        "        retriever = CohereRagRetriever(llm=ChatCohere())  # need to work on!\n",
        "\n",
        "    # cohere rerank...\n",
        "    compressor = CohereRerank(top_n=5, user_agent=\"my-app\")\n",
        "    compression_retriever = ContextualCompressionRetriever(\n",
        "        base_compressor=compressor, base_retriever=retriever\n",
        "    )\n",
        "\n",
        "    # please update to return source as well!\n",
        "    chain = RetrievalQA.from_chain_type(\n",
        "      llm=ChatCohere(), retriever=compression_retriever, return_source_documents=True\n",
        "    )\n",
        "    # chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    #   llm=ChatCohere(), retriever=compression_retriever\n",
        "    # )\n",
        "\n",
        "    return chain, retriever\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# purely thru co.chat end point\n",
        "def get_response_cohere(query, chat_history=[], docs=[]):\n",
        "    # format docs\n",
        "    docs_formatted = []\n",
        "    for d in docs:\n",
        "      doc = {\n",
        "          'title': d.metadata['source'],\n",
        "          'page_number': str(d.metadata['page_number']),\n",
        "          'snippet': d.page_content\n",
        "      }\n",
        "      docs_formatted.append(doc)\n",
        "\n",
        "    print(type(docs_formatted))\n",
        "\n",
        "    co = cohere.Client(COHERE_API_KEY)\n",
        "    response = co.chat(\n",
        "      chat_history=chat_history,\n",
        "      message=query,\n",
        "      documents=docs_formatted\n",
        "    )\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "SZYudzYtMiKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJFiztt7JZD3"
      },
      "source": [
        "## Main Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JjoyyvSsxcN",
        "outputId": "88a67bc8-bca2-4ffa-f6c5-f190f1c0b3ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104-92 Replacement of Noise Walls at Various Locations Proposal\n",
            "104-65 Peel King St E Bridges over Humber RFP\n",
            "105-100 Rehabilitation of Cochrane Street over CP Rail Bridge RFP\n",
            "251-30 DNS Rainbow Bridge Replacement RFP\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2._reader:Overwriting cache for 0 2700\n"
          ]
        }
      ],
      "source": [
        "files = get_files(PATH, count=None)\n",
        "\n",
        "documents = []\n",
        "for project in files:\n",
        "    try:\n",
        "        for fileobj in files[project]:\n",
        "            documents += get_document(fileobj, project)\n",
        "    except:\n",
        "        print(project)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTHQ9Yu_sqOc"
      },
      "outputs": [],
      "source": [
        "database = get_db(docs=documents, create=False, use_cohere=True, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVlW9PSEs5zM"
      },
      "outputs": [],
      "source": [
        "retrieval_chain, retriever = get_response(database)\n",
        "results = retrieval_chain(\n",
        "    {\"query\": \"Tell me about the past projects CFA done for the City of Brampton\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['source_documents']\n",
        "# ISSUE: we are not getting the metadata from weaviates database for some reason... (shit this is weird...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdmlCBHFEXF3",
        "outputId": "fc90b1b2-81ec-491b-a63c-c9d63b863cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='2020-269P - DETAILED DESIGN, CONTRACT ADMINISTRATION\\nAND CONSTRUCTION INSPECTION FOR CONVERSION OF\\nPRIVATE NOISE WALLS ON BOVAIRD DRIVE, WEST OF HIGHWAY\\n410, IN THE CITY OF BRAMPTON, PROJECT 19-4517\\nDate Issued: March 5, 2020 12:00 PM\\nVendor Details\\nCompany Name: Chisholm Fleming & Associates\\nAddress:317 Renfrew Dr., Suite 301\\nMarkham, Ontario L3R 9S8\\nContact: James Moffat\\nEmail: rfp@chisholmfleming.com\\nPhone: 905-474-1458 232\\nFax: 905-474-1458\\nHST#:\\nSubmission Details', metadata={'filename': '/content/drive/MyDrive/Cohere Hackathon/data/Proposal/104-85 Noise Walls on Bovaird West of 410/2020-269P Final Submission Complete.pdf', 'page_number': '1', 'source': '104-85 Noise Walls on Bovaird West of 410 Proposal', 'relevance_score': 0.30725408}),\n",
              " Document(page_content=\"Created On: Wednesday March 18, 2020 13:37:31\\nSubmitted On: Tuesday April 14, 2020 10:48:06\\nSubmitted By: James Moffat\\nEmail: rfp@chisholmfleming.com\\nTransaction #: 76e0c396-be77-4313-a8c6-f6778c8fdbdd\\nSubmitter's IP Address: 72.137.219.14\\nBid Number: 2020-269P Vendor Name: Chisholm Fleming & Associates\", metadata={'filename': '/content/drive/MyDrive/Cohere Hackathon/data/Proposal/104-85 Noise Walls on Bovaird West of 410/2020-269P Final Submission Complete.pdf', 'page_number': '1', 'source': '104-85 Noise Walls on Bovaird West of 410 Proposal', 'relevance_score': 0.0022343625})]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KZkbUCbkDDl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}